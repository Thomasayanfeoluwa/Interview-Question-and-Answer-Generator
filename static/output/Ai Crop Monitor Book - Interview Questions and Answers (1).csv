No.,Question,Answer
1,"Platform Overview: Describe the core purpose of the AI Crop Monitoring & Agricultural Intelligence Platform. What key AI capabilities does it integrate, and what are its primary design principles?","The AI Crop Monitoring & Agricultural Intelligence Platform is a professional-grade ecosystem for precision agriculture. It integrates computer vision, time-series forecasting, market analytics, explainable AI, and microfinance scoring into a single, modular, and scalable system. Its primary design principles involve combining edge computing with cloud-based retraining to make it both low-cost and scalable."
2,"Hybrid Approach: Explain the platform's core technical approach regarding computation and data processing, specifically mentioning how it balances edge computing and cloud-based retraining. What are the benefits of this approach?","The system combines edge computing, using offline models on phones, Raspberry Pi, or drones, with cloud-based retraining, utilizing Google Colab, Kaggle, or free-tier cloud. This approach makes it both low-cost and scalable."
3,You are tasked with conducting exploratory data analysis (EDA) and model prototyping. In which top-level directory would you place your work?,Notebooks/
4,Where should production-ready code for modular components like the recommendation engine reside?,Src/
5,"If you are developing scripts for model training, evaluation, and export (e.g., to ONNX), which directory is most appropriate?",Ai/
6,"Where would you find documentation for farmers, administrators, and deployment engineers, and what tools are recommended for generating it?","You would find documentation for farmers, administrators, and deployment engineers in the docs/ directory. Sphinx or MkDocs are recommended for generating this documentation from Markdown files."
7,"Which directory is dedicated to ensuring code quality and functionality before deployment, and what types of tests are expected there?","Use tests/ to ensure everything works before deployment. Implement unit tests with pytest, integration tests for API endpoints, and performance tests for model inference times."
8,"What is the purpose of Dockerfile, docker-compose.yml, docker-compose.prod.yml, and docker-compose.mlflow.yml in the project root?",Not found in context.
9,Continuous Learning: Describe the mechanism for continuous learning in the platform. How is farmer feedback collected and utilized for model improvement?,"Farmer feedback is collected into SQLite when offline and then synced to MongoDB Atlas. This feedback is used to retrain models monthly using Colab free GPUs, employing active learning strategies like uncertainty sampling."
10,Offline Mode: How does the platform enable offline functionality for remote farm usage? What specific technologies and model formats are used for edge inference and local data storage?,"The platform enables offline functionality for remote farm usage through edge inference and local data storage. For edge inference, compressed models in TensorFlow Lite (TFLite) or ONNX formats are deployed on mobile or edge devices like smartphones, Raspberry Pi, or drones, using tfliteruntime or ONNX Runtime for inference. Local data storage for offline data, including images, predictions, and recommendations, is managed using SQLite, with JSON as an alternative for simple metadata."
11,"Recommendations & Configuration: How are pesticide, fertilizer, and irrigation recommendations defined and generated? What file format and library are mentioned for managing these configurations?","Pesticide, fertilizer, and irrigation recommendations are defined by mapping in YAML/JSON configurations, specifically mentioned as src/config/treatments.yaml. These configurations are loaded using the PyYAML library, and recommendations are generated based on model outputs."
12,How does the platform address scalability for multi-farm dashboards?,"Build dashboards in Streamlit, fetch data from MongoDB Atlas for multi-farm views, and use Kubernetes for scaling."
13,"What is the compliance approach for logging farmer data, and what specific actions are taken to ensure trust and legal safety?",Encrypt farmer logs in MongoDB Atlas cropmonitoring collection; allow farmers to request deletion. Use PyMongo for data access and implement audit logs.
14,Edge AI Implementation: Detail how compressed models are deployed and used on edge devices. What runtimes are mentioned for cross-platform inference?,"Compressed models like ONNX and TFLite are deployed on smartphones, Raspberry Pi, or drones for local inference. The runtimes mentioned for cross-platform inference are ONNX Runtime and tfliteruntime."
15,"Satellite + Drone Fusion: Describe the process of fusing satellite and drone imagery. What libraries are mentioned for this task, and where is the metadata stored?",Process Sentinel-2 via Google Earth Engine or alternatives; fuse with drone images in fusionpipeline.py using libraries like rasterio for alignment. Metadata is stored in MongoDB Atlas imagesmetadata collection.
16,"Farm Health Score: How is the Farm Health Score computed, and where is it stored for dashboard display?",The Farm Health Score is computed as a weighted index (disease % + soil + rainfall) in backend/services/healthscore.py and stored in MongoDB Atlas farms collection for dashboard display.
17,"Voice Interfaces & AR Overlays: What technologies are mentioned for implementing voice interfaces and AR overlays, and how is data related to these features managed?","For voice interfaces, Whisper (offline STT) or Vosk are mentioned for local languages (Yoruba, Hausa, Igbo), and voice command logs are stored in MongoDB Atlas for analysis. For AR overlays, AR.js/ARCore are used to guide farmers visually, and AR metadata is stored in MongoDB Atlas imagesmetadata collection."
18,When should licensing and provenance be managed?,Every time you add or update datasets.
19,What tools and practices are used to maintain dataset provenance and ensure reproducibility?,"Maintain manifest.csv with source, license, date, sha256 checksum using pandas, and store metadata in MongoDB Atlas cropmonitoring collection. Use DVC for dataset versioning. Pin seeds and dependencies (requirements.txt, pyproject.toml), and version datasets with hashes using DVC or Git LFS, storing metadata in MongoDB Atlas."
20,What specific consent requirement is mentioned for farmer uploads?,Require farmer consent forms for uploads.
21,"Before training a supervised model, what steps are taken for annotation and label quality assurance?","Use CVAT or Roboflow for annotations, exporting in COCO or YOLO formats and storing in MongoDB Atlas imagesmetadata collection. Set clear guidelines for resolution (minimum 1024x1024) and label taxonomy (e.g., disease classes from PlantVillage). Ensure inter-annotator agreement is at least 0.75 (Cohen’s Kappa), computed using scikit-learn’s cohenkappascore."
22,"What metric is used to ensure inter-annotator agreement, and what is the target threshold?","Cohen’s Kappa, with a target threshold of greater than or equal to 0.75."
23,"Data Validation: How is data validation performed before training and deployment, and what tools are integrated into the CI/CD pipeline for this?","Data validation is performed by adding Great Expectations tests for correct file counts and schema checks, with expectations defined in greatexpectations/expectations/. This validates MongoDB Atlas data. Pytest is run in CI/CD pipelines and integrated with GitHub Actions for automated validation."
24,"Model Governance: What is a ""model card,"" and when is it generated? How is model metadata tracked and made accessible for multi-user setups?","A model card is a document (model-card.md) that stores the intended use, limitations, and metrics (accuracy, F1-score) of a model. It is generated at each model release. Model metadata is tracked in an MLflow registry and synced to MongoDB Atlas for multi-user access."
25,How is model drift detected after deployment?,Use Evidently AI to detect distribution drifts.
26,"What is the trigger for model retraining, and how is this process automated?","Retrain if macro-F1 drops below baseline. This process is automated with cron jobs or Airflow, and models are updated in MongoDB Atlas."
27,Describe the security measures for storing secrets and encrypting data at rest and in transit?,"Secrets are stored in Vault/GCP Secret Manager and accessed via API in code. Data is encrypted using AES-256 at rest and TLS in transit, utilizing MongoDB Atlas client-side field-level encryption."
28,"What data retention policy is mentioned, and how is it enforced using MongoDB Atlas?",Implement data retention policies (max 2 years). Use MongoDB Atlas queries to purge old data.
29,What are the stated Service Level Objectives (SLOs) for latency and uptime?,"Set latency p95 <200ms, uptime >=99.5%."
30,"What tools are used for monitoring, and where are metrics and logs stored?","Prometheus, Grafana, and OpenTelemetry are used for monitoring. Metrics and logs are stored in the MongoDB Atlas systemlogs collection."
31,"How do GitHub Actions contribute to the CI/CD process, specifically regarding model accuracy?",GitHub Actions run model accuracy checks before deployment and block deployment if model accuracy drops below a baseline.
32,"Explain the deployment strategy mentioned for production, including rollback triggers?","Canary rollout with rollback triggers, implemented using Kubernetes deployments."
33,What practices ensure the reproducibility of training runs?,"Pin seeds and dependencies using requirements.txt or pyproject.toml, and use random.seed(42) in code. Version datasets with hashes using DVC or Git LFS, storing metadata in MongoDB Atlas. Backup MongoDB Atlas weekly."
34,"How are datasets versioned, and what is the backup strategy for MongoDB Atlas?","Datasets are versioned with hashes using DVC or Git LFS, and metadata is stored in MongoDB Atlas. MongoDB Atlas is backed up weekly with a Recovery Point Objective (RPO) of 1 day and a Recovery Time Objective (RTO) of 4 hours, using mongodump for exports automated via cron."
35,"Deep Learning Models: For crop disease detection and weather/yield forecasting, what specific Deep Learning models are recommended?","For crop disease detection, CNNs (ResNet, EfficientNet) are recommended. For weather and yield forecasting, LSTM/GRU models are recommended."
36,When would you choose Streamlit versus Next.js with React for frontend development in this project?,"Streamlit is chosen for rapid development of dashboards and prototypes, ideal for data scientists to create interactive apps quickly. Next.js with React is chosen for production web applications, supporting server-side rendering, API routes, and static generation for performance."
37,"What framework is used for cross-platform mobile apps, and what specific mobile capabilities does it enable?",React Native is used for cross-platform mobile apps (iOS/Android) and enables native camera access and offline capabilities.
38,Which collection would store logs related to system monitoring and drift detection?,Systemlogs collection
39,"Describe the function of the /api/upload endpoint, including what it triggers and where it stores metadata?","Image upload, trigger inference, store metadata in MongoDB Atlas imagesmetadata."
40,"What is the purpose of the /api/forecast endpoint, and where are its results stored?","The purpose of the /api/forecast endpoint is to POST with farm data, and its results are stored in MongoDB Atlas yieldforecasts."
41,What is the purpose of this endpoint?,Not found in context.
42,How does it handle an incoming image file?,"When an image file is uploaded, it triggers inference and stores metadata in MongoDB Atlas imagesmetadata. The system reads the file content, decodes the image, performs a prediction, and then stores the image filename and the prediction result in the imagesmetadata collection. For offline scenarios, images are captured, saved to SQLite with metadata, local inference is run, results are stored in SQLite, and then synced to MongoDB Atlas when online."
43,"How does it interact with MongoDB Atlas, and what information is stored?","The system interacts with MongoDB Atlas as a centralized cloud database for multi-user access, dashboards, analytics, and persistent storage. The backend manages business logic, API endpoints, and background processing with MongoDB Atlas as the primary database. Edge devices sync local data from SQLite to MongoDB Atlas when online. Dashboards and analytics read from MongoDB Atlas. Information stored includes: - imagesmetadata: image paths, labels, GPS, drone info, AR metadata, satellite and drone fusion metadata. - farmerfeedback: user feedback for retraining and recommendation refinement, gamification points. - marketprices: scraped or API-based market data, historical trends. - loanrequests: microfinance and credit scoring data, loan request history and repayment. - yieldforecasts: predicted crop yields, weather API + LSTM model forecasts. - notifications: SMS/email/WhatsApp logs, alerts. - systemlogs: monitoring, drift detection, system metrics, errors, drifts, Evidently AI reports. - cropmonitoring: dataset metadata, model cards, encrypted farmer logs. - users: farmer consent forms for uploads with timestamps. - farms: farm health score. - model metadata: for tracking CI/CD for models."
44,"Deployment & Testing: How would you run the FastAPI backend locally, and what tools are recommended for scaling and load testing in production?","Run locally with uvicorn backend.api.main:app –reload. Scale with Gunicorn, deploy in Docker containers. For load testing, use Locust."
45,Caching Strategy: Explain the roles of SQLite and JSON for caching on edge devices. When would you choose one over the other?,"SQLite is used for local storage on edge devices for offline data such as images, predictions, and recommendations. JSON is an alternative lightweight format for simple metadata, chosen if SQLite is too heavy."
46,Phase 2 & 3 Features: What new AI capabilities are introduced in Phase 2 (3-6 months) and Phase 3 (6-12 months)?,"In Phase 2 (3-6 months), new AI capabilities include yield forecasting, a market pricing model, and microfinance scoring. In Phase 3 (6-12 months), these expand to integrating satellite and drone pipelines, and adding gamification and voice interfaces."
47,"Central vs. Local Database: Clearly differentiate the purpose and usage of MongoDB Atlas and SQLite in the platform's database strategy. Why is MongoDB Atlas considered the ""single source of truth""?","MongoDB Atlas serves as the centralized cloud database for multi-user access, dashboards, analytics, and persistent storage, holding all multi-user, cross-device, or long-term analytics. SQLite is used for temporary, local storage on mobile or edge devices to support offline-first operations and avoid blocking farm use when there is no internet. MongoDB Atlas is considered the single source of truth because SQLite acts as a temporary offline buffer, with all offline outputs eventually synced to MongoDB Atlas to maintain centralized data for analytics, dashboards, and retraining."
48,"Combined Workflow Benefits: What are the two main benefits of the combined workflow involving edge devices, SQLite, and MongoDB Atlas?","Ensures offline-first usability for farmers. Maintains centralized data in MongoDB Atlas for analytics, dashboards, and retraining."
49,"Local Simulation: If live satellite data access is unavailable for the MVP, how can local simulation be performed for raster images and feature extraction?","For raster images, use sample .tif or .png bands from AWS/Copernicus datasets and store them in data/satellite/ for local processing. For feature extraction, precompute indices like NDVI, EVI using rasterio or GDAL and save them as satellitefeatures.csv for ML model input."
50,"Which API is used for real-time weather data, and where are its results stored?","Open WeatherMap API is used for real-time and forecast weather, and its results are stored in MongoDB Atlas yieldforecasts."
51,"What services are used for sending SMS/WhatsApp and email notifications, and where are the logs stored?",Twilio API is used for SMS/WhatsApp notifications and Gmail API for email notifications. The logs for these notifications are stored in the MongoDB Atlas notifications collection.
52,"How are market prices collected, and what collection stores this data?","Market prices are collected via scraping using BeautifulSoup/Selenium or API-based market data, and this data is stored in the MongoDB Atlas marketprices collection."
53,"What tools are used for containerization, orchestration, and Infrastructure as Code (IaC)?","Docker for containerization, Kubernetes/Helm for orchestration, Terraform for IaC."
54,"Testing & QA: Beyond unit tests, what other types of testing are implemented, and what security checks are performed?","Beyond unit tests, integration testing is implemented to test API chains with MongoDB Atlas, and performance testing measures inference time and scalability. Security checks include OWASP scans and dependency checks with pip-audit."
